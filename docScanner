#include<opencv2/imgcodecs.hpp>
#include<opencv2/highgui.hpp>
#include<opencv2/imgproc.hpp>
#include<iostream>
using namespace std;
using namespace cv;


Mat imgOriginal, imgGray,imgBlur, imgCanny,imgThre,imgDil,imgWarp,imgCrop;
vector<Point> initialPoints, finalPoints; 
float w = 240, h = 596; //width & height of A4 size is 120 and 248 resp.

Mat preProcessing(Mat img) {
	 //preProcessing original image in order to obtain image dilation

	cvtColor(img, imgGray, COLOR_BGR2GRAY); 
	GaussianBlur(imgGray, imgBlur, Size(3, 3), 3, 0);
	Canny(imgBlur, imgCanny, 25, 75);
	Mat kernel = getStructuringElement(MORPH_RECT, Size(3, 3));
	dilate(imgCanny, imgDil, kernel);

	return imgDil;
}
vector<Point> detectContours(Mat image) {
	vector < vector<Point> >contours;
	vector<Vec4i> hierarchy;
	findContours(image, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_TC89_KCOS);
	vector<vector<Point>>conPoly(contours.size());
	vector<Rect>boundRect(contours.size());
	vector<Point> biggest;
	int areaMax=0;
	for (int i = 0; i < contours.size(); i++) {
		int area = contourArea(contours[i]);
		cout << area << endl;
		string objectType;
		if (area > 1000) {
			float peri = arcLength(contours[i], true);
			approxPolyDP(contours[i], conPoly[i],( 0.02 * peri), true);

			//Assuming that the documents will be rectangle in shape

			if (area > areaMax && conPoly[i].size()==4) {

				biggest = { conPoly[i][0],conPoly[i][1],conPoly[i][2],conPoly[i][3] };
				areaMax = area;
			}

		}
	}

	return biggest;

}

void drawPoints(vector<Point> points, Scalar color) {

	for (int i = 0; i < points.size(); i++) {
		circle(imgOriginal, points[i], 10, color, FILLED);
		putText(imgOriginal, to_string(i), points[i], FONT_HERSHEY_PLAIN, 3, color, 3);

	}

} 

vector<Point> reOrder(vector<Point> points) {
	vector<Point> newPoints;
	vector<int> sumPoints, subPoints;
	for (int i = 0; i < 4; i++) {

		sumPoints.push_back(points[i].x + points[i].y);
		subPoints.push_back(points[i].x - points[i].y);

	}
	newPoints.push_back(points[min_element(sumPoints.begin(), sumPoints.end()) - sumPoints.begin()]); //index 0
	newPoints.push_back(points[max_element(subPoints.begin(), subPoints.end()) - subPoints.begin()]);//index 1
	newPoints.push_back(points[min_element(subPoints.begin(), subPoints.end()) - subPoints.begin()]);//index 2
	newPoints.push_back(points[max_element(sumPoints.begin(), sumPoints.end()) - sumPoints.begin()]);//index 3

	return newPoints;
}

Mat getWarp(Mat img, vector<Point> points, float w, float h) {

	//Warping the image in order to get a good view of scanned document

	Point2f src[4] = { points[0], points[1], points[2], points[3] };//src=source points; dst=destination points
	Point2f dst[4] = { {0.0f,0.0f},{w,0.0f},{0.0f,h},{w,h} };
	Mat matrix = getPerspectiveTransform(src, dst);
	warpPerspective(img, imgWarp, matrix, Point(w, h));
	return imgWarp;


}

void main() {

	string path = "Resources/paper.jpg";
	imgOriginal = imread(path);
	imgThre = preProcessing(imgOriginal);
	drawPoints(finalPoints, Scalar(0, 255, 0));
	initialPoints = detectContours(imgThre);
	finalPoints = reOrder(initialPoints);

	imgWarp = getWarp(imgOriginal, finalPoints, w, h);
	Rect roi(5, 5, (w - (2 * 5)), (h - (2 * 5)));
	imgCrop = imgWarp(roi);
	
		imshow("Image", imgOriginal);
		imshow("Image Dilation ", imgThre);
		imshow("Image Warp", imgWarp);
		imshow("Image Crop", imgCrop);
		waitKey(0);
	
}
